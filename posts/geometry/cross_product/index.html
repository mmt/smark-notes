<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Useful Properties of Cross Product - sMark Notes</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta itemprop="name" content="Useful Properties of Cross Product">
<meta itemprop="description" content="This note is going to go important properties of what you might call the cross product matrix. For a vector $v \in \mathbb{R}^3$ we&rsquo;ll write $$[v]_\times = \begin{bmatrix} 0 &amp; -v_z &amp; v_y \\ v_z &amp; 0 &amp; -v_x \\ -v_y &amp; v_x &amp; 0\end{bmatrix}$$ to mean the $3\times 3$ matrix such that $[v]_\times w = v \times w$ for a all $w \in \mathbb{R}^3$.
These matrices are closely related to rotations due through the Rodrigues formula: $$ R(\theta, u) = \exp\left([\theta u ]_\times\right) = I &#43; \sin(\theta) [u]_\times &#43; (1 - \cos(\theta))[u]_\times^2.">
<meta itemprop="datePublished" content="2020-12-27T12:55:13-08:00" />
<meta itemprop="dateModified" content="2020-12-27T12:55:13-08:00" />
<meta itemprop="wordCount" content="959">



<meta itemprop="keywords" content="geometry,navigation," />
<meta property="og:title" content="Useful Properties of Cross Product" />
<meta property="og:description" content="This note is going to go important properties of what you might call the cross product matrix. For a vector $v \in \mathbb{R}^3$ we&rsquo;ll write $$[v]_\times = \begin{bmatrix} 0 &amp; -v_z &amp; v_y \\ v_z &amp; 0 &amp; -v_x \\ -v_y &amp; v_x &amp; 0\end{bmatrix}$$ to mean the $3\times 3$ matrix such that $[v]_\times w = v \times w$ for a all $w \in \mathbb{R}^3$.
These matrices are closely related to rotations due through the Rodrigues formula: $$ R(\theta, u) = \exp\left([\theta u ]_\times\right) = I &#43; \sin(\theta) [u]_\times &#43; (1 - \cos(\theta))[u]_\times^2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mmt.github.io/smark-notes/posts/geometry/cross_product/" />
<meta property="article:published_time" content="2020-12-27T12:55:13-08:00" />
<meta property="article:modified_time" content="2020-12-27T12:55:13-08:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Useful Properties of Cross Product"/>
<meta name="twitter:description" content="This note is going to go important properties of what you might call the cross product matrix. For a vector $v \in \mathbb{R}^3$ we&rsquo;ll write $$[v]_\times = \begin{bmatrix} 0 &amp; -v_z &amp; v_y \\ v_z &amp; 0 &amp; -v_x \\ -v_y &amp; v_x &amp; 0\end{bmatrix}$$ to mean the $3\times 3$ matrix such that $[v]_\times w = v \times w$ for a all $w \in \mathbb{R}^3$.
These matrices are closely related to rotations due through the Rodrigues formula: $$ R(\theta, u) = \exp\left([\theta u ]_\times\right) = I &#43; \sin(\theta) [u]_\times &#43; (1 - \cos(\theta))[u]_\times^2."/>
<link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="screen" href="https://mmt.github.io/smark-notes/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://mmt.github.io/smark-notes/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://mmt.github.io/smark-notes/css/dark.css" />

	
		<script src="https://mmt.github.io/smark-notes/js/main.js"></script>
   <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true,
      tags: 'ams'

    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>

<body>
	<div class="container wrapper">
		<div class="header">
	
	<h1 class="site-title"><a href="https://mmt.github.io/smark-notes/">sMark Notes</a></h1>
	<div class="site-description"><p>Mark M. Tobenkin&rsquo;s Notes on Mathematics and Other Topics</p><nav class="nav social">
			<ul class="flat"></ul>
		</nav></div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/smark-notes/">Home</a>
			</li>
			
			<li>
				<a href="/smark-notes/posts">All posts</a>
			</li>
			
			<li>
				<a href="/smark-notes/about">About</a>
			</li>
			
			<li>
				<a href="/smark-notes/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post">
			<div class="post-header">
				
					<div class="meta">
						<div class="date">
							<span class="day">27</span>
							<span class="rest">Dec 2020</span>
						</div>
					</div>
				
				<div class="matter">
					<h1 class="title">Useful Properties of Cross Product</h1>
				</div>
			</div>
					
			<div class="markdown">
				<p>This note is going to go important properties of what you might call the cross product matrix.
For a vector $v \in \mathbb{R}^3$ we&rsquo;ll write $$[v]_\times = \begin{bmatrix} 0 &amp; -v_z &amp; v_y \\ v_z &amp; 0 &amp; -v_x \\ -v_y &amp; v_x &amp; 0\end{bmatrix}$$ to mean the $3\times 3$ matrix such that $[v]_\times w = v \times w$ for a all $w \in \mathbb{R}^3$.</p>
<p>These matrices are closely related to rotations due through the Rodrigues formula:
$$
R(\theta, u) = \exp\left([\theta u ]_\times\right) = I + \sin(\theta) [u]_\times + (1 - \cos(\theta))[u]_\times^2.
$$
Here the matrix $R(\theta, a)$ is a rotation about the unit norm vector $a$ by an angle $\theta$.</p>
<h1 id="relationship-to-linear-transforms">Relationship to Linear Transforms</h1>
<p>Important properties of the cross-product matrix can be derived from its relationship two the determinant:
$$
\det\left(\begin{bmatrix}
u &amp; v &amp; w
\end{bmatrix}\right) = u^T [v]_\times w
\qquad \forall ; u, v, w \in \mathbb{R}^3.$$
This can be easily proven using expansion by minors along the first column.
Given an arbitrary invertible matrix $M \in \mathbb{R}^{3 \times 3}$ we therefore have:</p>
<p>$$
\det\left(M\begin{bmatrix}
u &amp; v &amp; w
\end{bmatrix}\right) = u^T\left(M^T [Mv]_\times M\right)w
\qquad \forall ; u, v, w \in \mathbb{R}^3.$$</p>
<p>But basic properties of the determinant also give use
$$
\det\left(M\begin{bmatrix}
u &amp; v &amp; w
\end{bmatrix}\right) = \det(M) u^T [v]_\times w
\qquad \forall ; u, v, w \in \mathbb{R}^3.$$
Since this holds for all $u$ and $v$ we can conclude that:</p>
<p>$$ \det(M)  M^{-T} [v]_\times = [ Mv ]_\times M \qquad \forall; v \in \mathbb{R}^3, M \in GL(3).$$</p>
<p>This identity is particularly useful when $M = R$ where $R$ is an element of $SO(3)$ so that $R^T = R^{-1}$ and $\det(R) = 1$:</p>
<p>$$R [v]_\times = [ Rv ]_\times R \qquad \forall ; v \in \mathbb{R}^3, R \in SO(3).$$</p>
<h1 id="algebraic-properties">Algebraic Properties</h1>
<h2 id="anti-symmetry">Anti-symmetry</h2>
<p>It is easy to verify that:
$$
[v]_\times u = -[u]_\times v.
$$</p>
<h2 id="lie-bracket">Lie Bracket</h2>
<p>The following relationship is frequently applied in navigation equations:
$$ [[u]_\times v]_\times = vu^T - uv^T $$
It can be verified explicitly (as a hint, the anti-symmetry and bilinearity of the expression means it is sufficient to test the result for the pairs $(u, v) \in \{(e_x, e_y), (e_y, e_z), (e_x, e_z)\}$).</p>
<h2 id="power-relationships">Power Relationships</h2>
<p>One of the most useful identities working with cross-product matrices is:
$$
\begin{equation}
[u]_\times [v]_\times = vu^T - u^T v I
\end{equation}
$$
This is not too painful to verify explicitly.  We see from this and the Lie Bracket property that:</p>
<p>$$
\begin{equation}
[u]_\times [v]_\times - [v]_\times [u]_\times = vu^T - uv^T =\left[[u]_\times v\right]_\times
\end{equation}
$$</p>
<p>For a unit vector $u \in \mathbb{R}^3$ Equation (1) establishes an important algebraic relationship:</p>
<p>$$
\begin{align}
[u ]_\times^3 &amp;= (uu^T - I) [u]_\times = -[u]_\times \\<br>
[u ]_\times^4 &amp;= -[u]_\times^3 [u]_\times = -[u]_\times^2
\end{align}
$$
This makes it clear that any power series in $[u]_x$ can always be rewritten in at most three terms:</p>
<p>$$
\alpha I + \beta [u]_\times + \gamma [u]_\times^2
$$</p>
<p>I find it more useful to write such expressions as:</p>
<p>$$
a I + b [u]_\times + c uu^T
$$
with $a = \alpha - \gamma$, $b = \beta$ and $c = \gamma$.</p>
<p>It is also useful to note that the inverse of such a matrix (when it exists) can be written:
$$
(a I + b [u]_\times + c uu^T)^{-1} = d I + e [u]_\times + f uu^T,
$$
with:
$$
\begin{bmatrix}d \\ e \\ f\end{bmatrix}
= \frac{1}{a^2+b^2}\begin{bmatrix}a \\ -b \\ \frac{b^2-ca}{a+c}\end{bmatrix}.
$$</p>
<blockquote>
<p><em>Proof:</em> We explicitly expand the product of these two matrices:
$$
\begin{gather}
(a I + b [u]_\times + cuu^T) (d I + e [u]_\times + f uu^T) \\<br>
=\\<br>
ad I + ae [u]_\times + af uu^T + bd [u]_\times + be uu^T - be I + c(d+f) uu^T
\end{gather}
$$
For the second matrix to be the inverse of the first, we require that:
$$
\begin{bmatrix}
a &amp; -b &amp; 0 \\<br>
b &amp;  a&amp; 0 \\<br>
c &amp; b &amp; a+c
\end{bmatrix}
\begin{bmatrix}
d \\ e \\ f
\end{bmatrix} = \begin{bmatrix}1 \\ 0 \\ 0\end{bmatrix}
$$
The result can then be found by using the general matrix identity:
$$
\begin{bmatrix}
A &amp; 0 \\<br>
B &amp; C
\end{bmatrix}^{-1} = \begin{bmatrix}
A^{-1} &amp; 0 \\<br>
-C^{-1}BA^{-1} &amp; C^{-1}
\end{bmatrix}.
$$</p>
</blockquote>
<h1 id="eigenvector-analysis">Eigenvector Analysis</h1>
<p>First, it is easy to verify that $[u]_\times u = 0$ so that $u$
itself is an eigenvector with eigenvalue 0.</p>
<p>If $u = 0$ then all the eigenvalues are trivially zero.
Otherwise,  let $v$ be any vector orthogonal to $u$ and let $w =\frac{1}{\|u\|} [u]_\times v$.
Then $u + j w$ is an eigenvector with eigenvalue $-j\|v\|$:
$$
\begin{align}
[u]_x (v + jw) &amp;= \|u\| w + j [u]_x w\\<br>
&amp;=  \|u\|w + j \frac{1}{\|u\|}[u]_x^2 v \\<br>
&amp;=  \|u\|w + j \frac{1}{\|u\|}(uu^T - \|u\|^2 I) v \\<br>
&amp;=  \|u\|\left(w - j  v \right) = -j\|u\|\left(v+jw\right).
\end{align}
$$
That $v - jw$ is an eigenvector with eigenvalue $-j\|u\|$ can be shown similarly.</p>
<p>This line or reasoning can be made more concrete by analyzing the
matrix $[e_x]_\times$ with $u = e_y$ and $w = e_z$, and then
concluding that the resulting analysis can be transfered to an
arbitrary $[v]_\times$ by a rotation matrix and scaling.</p>
<p>Armed with this eigenvector analysis we can revisit the matrices of the form:
$$
aI + b [u]_\times + cuu^T.
$$
We see that these matrices have the same eigenvectors as $[u]_\times$ owing to $u^Tv = u^Tw = 0$.
When $|u| = 1$ we can see that the eigen-vector / eigen-value pairs are:</p>
<ul>
<li>$(u, a + c)$</li>
<li>$(v + jw, a-bj)$</li>
<li>$(v - jw, a+bj)$</li>
</ul>
<p>This leads to a second approach to finding our general equation for
the inverse of these matrices, based on inverting these eigenvalues
and term-matching to find $(d, e, f)$ from the prior section.</p>

			</div>

			<div class="tags">
				
					
						<ul class="flat">
							
							<li><a href="/smark-notes/tags/geometry">geometry</a></li>
							
							<li><a href="/smark-notes/tags/navigation">navigation</a></li>
							
						</ul>
					
				
			</div></div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div>2020  © Copyright Mark M. Tobenkin 2020 |  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>


</body>
</html>
